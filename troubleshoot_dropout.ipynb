{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/local/ML/TRAIN/jax/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import FlaxGPT2LMHeadModel\n",
    "\n",
    "model = FlaxGPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('transformer', 'h', '0', 'attn', 'c_attn', 'bias'), ('transformer', 'h', '0', 'attn', 'c_attn', 'kernel'), ('transformer', 'h', '0', 'attn', 'c_proj', 'bias'), ('transformer', 'h', '0', 'attn', 'c_proj', 'kernel'), ('transformer', 'h', '0', 'ln_1', 'bias'), ('transformer', 'h', '0', 'ln_1', 'scale'), ('transformer', 'h', '0', 'ln_2', 'bias'), ('transformer', 'h', '0', 'ln_2', 'scale'), ('transformer', 'h', '0', 'mlp', 'c_fc', 'bias'), ('transformer', 'h', '0', 'mlp', 'c_fc', 'kernel'), ('transformer', 'h', '0', 'mlp', 'c_proj', 'bias'), ('transformer', 'h', '0', 'mlp', 'c_proj', 'kernel'), ('transformer', 'h', '1', 'attn', 'c_attn', 'bias'), ('transformer', 'h', '1', 'attn', 'c_attn', 'kernel'), ('transformer', 'h', '1', 'attn', 'c_proj', 'bias'), ('transformer', 'h', '1', 'attn', 'c_proj', 'kernel'), ('transformer', 'h', '1', 'ln_1', 'bias'), ('transformer', 'h', '1', 'ln_1', 'scale'), ('transformer', 'h', '1', 'ln_2', 'bias'), ('transformer', 'h', '1', 'ln_2', 'scale'), ('transformer', 'h', '1', 'mlp', 'c_fc', 'bias'), ('transformer', 'h', '1', 'mlp', 'c_fc', 'kernel'), ('transformer', 'h', '1', 'mlp', 'c_proj', 'bias'), ('transformer', 'h', '1', 'mlp', 'c_proj', 'kernel'), ('transformer', 'h', '10', 'attn', 'c_attn', 'bias'), ('transformer', 'h', '10', 'attn', 'c_attn', 'kernel'), ('transformer', 'h', '10', 'attn', 'c_proj', 'bias'), ('transformer', 'h', '10', 'attn', 'c_proj', 'kernel'), ('transformer', 'h', '10', 'ln_1', 'bias'), ('transformer', 'h', '10', 'ln_1', 'scale'), ('transformer', 'h', '10', 'ln_2', 'bias'), ('transformer', 'h', '10', 'ln_2', 'scale'), ('transformer', 'h', '10', 'mlp', 'c_fc', 'bias'), ('transformer', 'h', '10', 'mlp', 'c_fc', 'kernel'), ('transformer', 'h', '10', 'mlp', 'c_proj', 'bias'), ('transformer', 'h', '10', 'mlp', 'c_proj', 'kernel'), ('transformer', 'h', '11', 'attn', 'c_attn', 'bias'), ('transformer', 'h', '11', 'attn', 'c_attn', 'kernel'), ('transformer', 'h', '11', 'attn', 'c_proj', 'bias'), ('transformer', 'h', '11', 'attn', 'c_proj', 'kernel'), ('transformer', 'h', '11', 'ln_1', 'bias'), ('transformer', 'h', '11', 'ln_1', 'scale'), ('transformer', 'h', '11', 'ln_2', 'bias'), ('transformer', 'h', '11', 'ln_2', 'scale'), ('transformer', 'h', '11', 'mlp', 'c_fc', 'bias'), ('transformer', 'h', '11', 'mlp', 'c_fc', 'kernel'), ('transformer', 'h', '11', 'mlp', 'c_proj', 'bias'), ('transformer', 'h', '11', 'mlp', 'c_proj', 'kernel'), ('transformer', 'h', '2', 'attn', 'c_attn', 'bias'), ('transformer', 'h', '2', 'attn', 'c_attn', 'kernel'), ('transformer', 'h', '2', 'attn', 'c_proj', 'bias'), ('transformer', 'h', '2', 'attn', 'c_proj', 'kernel'), ('transformer', 'h', '2', 'ln_1', 'bias'), ('transformer', 'h', '2', 'ln_1', 'scale'), ('transformer', 'h', '2', 'ln_2', 'bias'), ('transformer', 'h', '2', 'ln_2', 'scale'), ('transformer', 'h', '2', 'mlp', 'c_fc', 'bias'), ('transformer', 'h', '2', 'mlp', 'c_fc', 'kernel'), ('transformer', 'h', '2', 'mlp', 'c_proj', 'bias'), ('transformer', 'h', '2', 'mlp', 'c_proj', 'kernel'), ('transformer', 'h', '3', 'attn', 'c_attn', 'bias'), ('transformer', 'h', '3', 'attn', 'c_attn', 'kernel'), ('transformer', 'h', '3', 'attn', 'c_proj', 'bias'), ('transformer', 'h', '3', 'attn', 'c_proj', 'kernel'), ('transformer', 'h', '3', 'ln_1', 'bias'), ('transformer', 'h', '3', 'ln_1', 'scale'), ('transformer', 'h', '3', 'ln_2', 'bias'), ('transformer', 'h', '3', 'ln_2', 'scale'), ('transformer', 'h', '3', 'mlp', 'c_fc', 'bias'), ('transformer', 'h', '3', 'mlp', 'c_fc', 'kernel'), ('transformer', 'h', '3', 'mlp', 'c_proj', 'bias'), ('transformer', 'h', '3', 'mlp', 'c_proj', 'kernel'), ('transformer', 'h', '4', 'attn', 'c_attn', 'bias'), ('transformer', 'h', '4', 'attn', 'c_attn', 'kernel'), ('transformer', 'h', '4', 'attn', 'c_proj', 'bias'), ('transformer', 'h', '4', 'attn', 'c_proj', 'kernel'), ('transformer', 'h', '4', 'ln_1', 'bias'), ('transformer', 'h', '4', 'ln_1', 'scale'), ('transformer', 'h', '4', 'ln_2', 'bias'), ('transformer', 'h', '4', 'ln_2', 'scale'), ('transformer', 'h', '4', 'mlp', 'c_fc', 'bias'), ('transformer', 'h', '4', 'mlp', 'c_fc', 'kernel'), ('transformer', 'h', '4', 'mlp', 'c_proj', 'bias'), ('transformer', 'h', '4', 'mlp', 'c_proj', 'kernel'), ('transformer', 'h', '5', 'attn', 'c_attn', 'bias'), ('transformer', 'h', '5', 'attn', 'c_attn', 'kernel'), ('transformer', 'h', '5', 'attn', 'c_proj', 'bias'), ('transformer', 'h', '5', 'attn', 'c_proj', 'kernel'), ('transformer', 'h', '5', 'ln_1', 'bias'), ('transformer', 'h', '5', 'ln_1', 'scale'), ('transformer', 'h', '5', 'ln_2', 'bias'), ('transformer', 'h', '5', 'ln_2', 'scale'), ('transformer', 'h', '5', 'mlp', 'c_fc', 'bias'), ('transformer', 'h', '5', 'mlp', 'c_fc', 'kernel'), ('transformer', 'h', '5', 'mlp', 'c_proj', 'bias'), ('transformer', 'h', '5', 'mlp', 'c_proj', 'kernel'), ('transformer', 'h', '6', 'attn', 'c_attn', 'bias'), ('transformer', 'h', '6', 'attn', 'c_attn', 'kernel'), ('transformer', 'h', '6', 'attn', 'c_proj', 'bias'), ('transformer', 'h', '6', 'attn', 'c_proj', 'kernel'), ('transformer', 'h', '6', 'ln_1', 'bias'), ('transformer', 'h', '6', 'ln_1', 'scale'), ('transformer', 'h', '6', 'ln_2', 'bias'), ('transformer', 'h', '6', 'ln_2', 'scale'), ('transformer', 'h', '6', 'mlp', 'c_fc', 'bias'), ('transformer', 'h', '6', 'mlp', 'c_fc', 'kernel'), ('transformer', 'h', '6', 'mlp', 'c_proj', 'bias'), ('transformer', 'h', '6', 'mlp', 'c_proj', 'kernel'), ('transformer', 'h', '7', 'attn', 'c_attn', 'bias'), ('transformer', 'h', '7', 'attn', 'c_attn', 'kernel'), ('transformer', 'h', '7', 'attn', 'c_proj', 'bias'), ('transformer', 'h', '7', 'attn', 'c_proj', 'kernel'), ('transformer', 'h', '7', 'ln_1', 'bias'), ('transformer', 'h', '7', 'ln_1', 'scale'), ('transformer', 'h', '7', 'ln_2', 'bias'), ('transformer', 'h', '7', 'ln_2', 'scale'), ('transformer', 'h', '7', 'mlp', 'c_fc', 'bias'), ('transformer', 'h', '7', 'mlp', 'c_fc', 'kernel'), ('transformer', 'h', '7', 'mlp', 'c_proj', 'bias'), ('transformer', 'h', '7', 'mlp', 'c_proj', 'kernel'), ('transformer', 'h', '8', 'attn', 'c_attn', 'bias'), ('transformer', 'h', '8', 'attn', 'c_attn', 'kernel'), ('transformer', 'h', '8', 'attn', 'c_proj', 'bias'), ('transformer', 'h', '8', 'attn', 'c_proj', 'kernel'), ('transformer', 'h', '8', 'ln_1', 'bias'), ('transformer', 'h', '8', 'ln_1', 'scale'), ('transformer', 'h', '8', 'ln_2', 'bias'), ('transformer', 'h', '8', 'ln_2', 'scale'), ('transformer', 'h', '8', 'mlp', 'c_fc', 'bias'), ('transformer', 'h', '8', 'mlp', 'c_fc', 'kernel'), ('transformer', 'h', '8', 'mlp', 'c_proj', 'bias'), ('transformer', 'h', '8', 'mlp', 'c_proj', 'kernel'), ('transformer', 'h', '9', 'attn', 'c_attn', 'bias'), ('transformer', 'h', '9', 'attn', 'c_attn', 'kernel'), ('transformer', 'h', '9', 'attn', 'c_proj', 'bias'), ('transformer', 'h', '9', 'attn', 'c_proj', 'kernel'), ('transformer', 'h', '9', 'ln_1', 'bias'), ('transformer', 'h', '9', 'ln_1', 'scale'), ('transformer', 'h', '9', 'ln_2', 'bias'), ('transformer', 'h', '9', 'ln_2', 'scale'), ('transformer', 'h', '9', 'mlp', 'c_fc', 'bias'), ('transformer', 'h', '9', 'mlp', 'c_fc', 'kernel'), ('transformer', 'h', '9', 'mlp', 'c_proj', 'bias'), ('transformer', 'h', '9', 'mlp', 'c_proj', 'kernel'), ('transformer', 'ln_f', 'bias'), ('transformer', 'ln_f', 'scale'), ('transformer', 'wpe', 'embedding'), ('transformer', 'wte', 'embedding')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flax\n",
    "\n",
    "type(model.params)\n",
    "flax.traverse_util.flatten_dict(model.params).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n",
      "Length of prepared JAX modules dict: 89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([('drop', 'rngs', 'default', 'count'), ('drop', 'rngs', 'default', 'key'), ('h', 0, 'attn', 'c_attn', 'bias'), ('h', 0, 'attn', 'c_attn', 'kernel'), ('h', 0, 'attn', 'c_proj', 'bias'), ('h', 0, 'attn', 'c_proj', 'kernel'), ('h', 0, 'ln_1', 'bias'), ('h', 0, 'ln_1', 'scale'), ('h', 0, 'ln_2', 'bias'), ('h', 0, 'ln_2', 'scale'), ('h', 0, 'mlp', 'c_fc', 'bias'), ('h', 0, 'mlp', 'c_fc', 'kernel'), ('h', 0, 'mlp', 'c_proj', 'bias'), ('h', 0, 'mlp', 'c_proj', 'kernel'), ('h', 1, 'attn', 'c_attn', 'bias'), ('h', 1, 'attn', 'c_attn', 'kernel'), ('h', 1, 'attn', 'c_proj', 'bias'), ('h', 1, 'attn', 'c_proj', 'kernel'), ('h', 1, 'ln_1', 'bias'), ('h', 1, 'ln_1', 'scale'), ('h', 1, 'ln_2', 'bias'), ('h', 1, 'ln_2', 'scale'), ('h', 1, 'mlp', 'c_fc', 'bias'), ('h', 1, 'mlp', 'c_fc', 'kernel'), ('h', 1, 'mlp', 'c_proj', 'bias'), ('h', 1, 'mlp', 'c_proj', 'kernel'), ('h', 2, 'attn', 'c_attn', 'bias'), ('h', 2, 'attn', 'c_attn', 'kernel'), ('h', 2, 'attn', 'c_proj', 'bias'), ('h', 2, 'attn', 'c_proj', 'kernel'), ('h', 2, 'ln_1', 'bias'), ('h', 2, 'ln_1', 'scale'), ('h', 2, 'ln_2', 'bias'), ('h', 2, 'ln_2', 'scale'), ('h', 2, 'mlp', 'c_fc', 'bias'), ('h', 2, 'mlp', 'c_fc', 'kernel'), ('h', 2, 'mlp', 'c_proj', 'bias'), ('h', 2, 'mlp', 'c_proj', 'kernel'), ('h', 3, 'attn', 'c_attn', 'bias'), ('h', 3, 'attn', 'c_attn', 'kernel'), ('h', 3, 'attn', 'c_proj', 'bias'), ('h', 3, 'attn', 'c_proj', 'kernel'), ('h', 3, 'ln_1', 'bias'), ('h', 3, 'ln_1', 'scale'), ('h', 3, 'ln_2', 'bias'), ('h', 3, 'ln_2', 'scale'), ('h', 3, 'mlp', 'c_fc', 'bias'), ('h', 3, 'mlp', 'c_fc', 'kernel'), ('h', 3, 'mlp', 'c_proj', 'bias'), ('h', 3, 'mlp', 'c_proj', 'kernel'), ('h', 4, 'attn', 'c_attn', 'bias'), ('h', 4, 'attn', 'c_attn', 'kernel'), ('h', 4, 'attn', 'c_proj', 'bias'), ('h', 4, 'attn', 'c_proj', 'kernel'), ('h', 4, 'ln_1', 'bias'), ('h', 4, 'ln_1', 'scale'), ('h', 4, 'ln_2', 'bias'), ('h', 4, 'ln_2', 'scale'), ('h', 4, 'mlp', 'c_fc', 'bias'), ('h', 4, 'mlp', 'c_fc', 'kernel'), ('h', 4, 'mlp', 'c_proj', 'bias'), ('h', 4, 'mlp', 'c_proj', 'kernel'), ('h', 5, 'attn', 'c_attn', 'bias'), ('h', 5, 'attn', 'c_attn', 'kernel'), ('h', 5, 'attn', 'c_proj', 'bias'), ('h', 5, 'attn', 'c_proj', 'kernel'), ('h', 5, 'ln_1', 'bias'), ('h', 5, 'ln_1', 'scale'), ('h', 5, 'ln_2', 'bias'), ('h', 5, 'ln_2', 'scale'), ('h', 5, 'mlp', 'c_fc', 'bias'), ('h', 5, 'mlp', 'c_fc', 'kernel'), ('h', 5, 'mlp', 'c_proj', 'bias'), ('h', 5, 'mlp', 'c_proj', 'kernel'), ('h', 6, 'attn', 'c_attn', 'bias'), ('h', 6, 'attn', 'c_attn', 'kernel'), ('h', 6, 'attn', 'c_proj', 'bias'), ('h', 6, 'attn', 'c_proj', 'kernel'), ('h', 6, 'ln_1', 'bias'), ('h', 6, 'ln_1', 'scale'), ('h', 6, 'ln_2', 'bias'), ('h', 6, 'ln_2', 'scale'), ('h', 6, 'mlp', 'c_fc', 'bias'), ('h', 6, 'mlp', 'c_fc', 'kernel'), ('h', 6, 'mlp', 'c_proj', 'bias'), ('h', 6, 'mlp', 'c_proj', 'kernel'), ('h', 7, 'attn', 'c_attn', 'bias'), ('h', 7, 'attn', 'c_attn', 'kernel'), ('h', 7, 'attn', 'c_proj', 'bias'), ('h', 7, 'attn', 'c_proj', 'kernel'), ('h', 7, 'ln_1', 'bias'), ('h', 7, 'ln_1', 'scale'), ('h', 7, 'ln_2', 'bias'), ('h', 7, 'ln_2', 'scale'), ('h', 7, 'mlp', 'c_fc', 'bias'), ('h', 7, 'mlp', 'c_fc', 'kernel'), ('h', 7, 'mlp', 'c_proj', 'bias'), ('h', 7, 'mlp', 'c_proj', 'kernel'), ('h', 8, 'attn', 'c_attn', 'bias'), ('h', 8, 'attn', 'c_attn', 'kernel'), ('h', 8, 'attn', 'c_proj', 'bias'), ('h', 8, 'attn', 'c_proj', 'kernel'), ('h', 8, 'ln_1', 'bias'), ('h', 8, 'ln_1', 'scale'), ('h', 8, 'ln_2', 'bias'), ('h', 8, 'ln_2', 'scale'), ('h', 8, 'mlp', 'c_fc', 'bias'), ('h', 8, 'mlp', 'c_fc', 'kernel'), ('h', 8, 'mlp', 'c_proj', 'bias'), ('h', 8, 'mlp', 'c_proj', 'kernel'), ('h', 9, 'attn', 'c_attn', 'bias'), ('h', 9, 'attn', 'c_attn', 'kernel'), ('h', 9, 'attn', 'c_proj', 'bias'), ('h', 9, 'attn', 'c_proj', 'kernel'), ('h', 9, 'ln_1', 'bias'), ('h', 9, 'ln_1', 'scale'), ('h', 9, 'ln_2', 'bias'), ('h', 9, 'ln_2', 'scale'), ('h', 9, 'mlp', 'c_fc', 'bias'), ('h', 9, 'mlp', 'c_fc', 'kernel'), ('h', 9, 'mlp', 'c_proj', 'bias'), ('h', 9, 'mlp', 'c_proj', 'kernel'), ('h', 10, 'attn', 'c_attn', 'bias'), ('h', 10, 'attn', 'c_attn', 'kernel'), ('h', 10, 'attn', 'c_proj', 'bias'), ('h', 10, 'attn', 'c_proj', 'kernel'), ('h', 10, 'ln_1', 'bias'), ('h', 10, 'ln_1', 'scale'), ('h', 10, 'ln_2', 'bias'), ('h', 10, 'ln_2', 'scale'), ('h', 10, 'mlp', 'c_fc', 'bias'), ('h', 10, 'mlp', 'c_fc', 'kernel'), ('h', 10, 'mlp', 'c_proj', 'bias'), ('h', 10, 'mlp', 'c_proj', 'kernel'), ('h', 11, 'attn', 'c_attn', 'bias'), ('h', 11, 'attn', 'c_attn', 'kernel'), ('h', 11, 'attn', 'c_proj', 'bias'), ('h', 11, 'attn', 'c_proj', 'kernel'), ('h', 11, 'ln_1', 'bias'), ('h', 11, 'ln_1', 'scale'), ('h', 11, 'ln_2', 'bias'), ('h', 11, 'ln_2', 'scale'), ('h', 11, 'mlp', 'c_fc', 'bias'), ('h', 11, 'mlp', 'c_fc', 'kernel'), ('h', 11, 'mlp', 'c_proj', 'bias'), ('h', 11, 'mlp', 'c_proj', 'kernel'), ('lm_head', 'bias'), ('lm_head', 'kernel'), ('ln_f', 'bias'), ('ln_f', 'scale'), ('wpe', 'embedding'), ('wte', 'embedding')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt2 import GPT\n",
    "import flax.nnx as nnx\n",
    "\n",
    "model = GPT.from_pretrained(\"gpt2\")\n",
    "model.train()\n",
    "nnx.state(model).flat_state().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have one ackward Dropout here that is causing the checkpointing to fail. No idea why the other Dropout modules dont have state!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('inner',\n",
       "  'inner_dropout',\n",
       "  'rngs'): Array((), dtype=key<fry>) overlaying:\n",
       " [3099025716 3811338087],\n",
       " ('outer_dropout',\n",
       "  'rngs'): Array((), dtype=key<fry>) overlaying:\n",
       " [ 862470802 3115470296]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flax.nnx as nnx\n",
    "import jax\n",
    "\n",
    "\n",
    "class Inner(nnx.Module):\n",
    "    def __init__(self, rngs) -> None:\n",
    "        super().__init__()\n",
    "        self.inner_dropout = nnx.Dropout(0.1, rngs=rngs)\n",
    "\n",
    "\n",
    "class Outer(nnx.Module):\n",
    "    def __init__(self, rngs) -> None:\n",
    "        super().__init__()\n",
    "        rngs, inner_dropout_key, outer_dropout_key = jax.random.split(rngs.key(), 3)\n",
    "        self.outer_dropout = nnx.Dropout(0.2, rngs=outer_dropout_key)\n",
    "        self.inner = Inner(inner_dropout_key)\n",
    "\n",
    "\n",
    "outer = Outer(nnx.Rngs(0))\n",
    "nnx.state(outer).flat_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split keys appears to add state for all dropouts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('inner',\n",
       "  'inner_dropout',\n",
       "  'rngs',\n",
       "  'default',\n",
       "  'count'): VariableState(\n",
       "   type=RngCount,\n",
       "   value=Array(0, dtype=uint32),\n",
       "   tag='default'\n",
       " ),\n",
       " ('inner',\n",
       "  'inner_dropout',\n",
       "  'rngs',\n",
       "  'default',\n",
       "  'key'): VariableState(\n",
       "   type=RngKey,\n",
       "   value=Array((), dtype=key<fry>) overlaying:\n",
       "   [0 0],\n",
       "   tag='default'\n",
       " )}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Inner1(nnx.Module):\n",
    "    def __init__(self, rngs) -> None:\n",
    "        super().__init__()\n",
    "        self.inner_dropout = nnx.Dropout(0.1, rngs=rngs)\n",
    "\n",
    "\n",
    "class Outer1(nnx.Module):\n",
    "    def __init__(self, rngs) -> None:\n",
    "        super().__init__()\n",
    "        self.outer_dropout = nnx.Dropout(0.2, rngs=rngs)\n",
    "        self.inner = Inner1(rngs)\n",
    "\n",
    "\n",
    "outer = Outer1(nnx.Rngs(0))\n",
    "nnx.state(outer).flat_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VariableState(\n",
       "  type=RngKey,\n",
       "  value=Array((), dtype=key<fry>) overlaying:\n",
       "  [0 0],\n",
       "  tag='default'\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnx.state(outer).flat_state()[(\"inner\", \"inner_dropout\", \"rngs\", \"default\", \"key\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only one Dropout gets state, no idea how that one is chosen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of prepared JAX modules dict: 89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VariableState(\n",
       "  type=RngKey,\n",
       "  value=Array((), dtype=key<fry>) overlaying:\n",
       "  [0 0],\n",
       "  tag='default'\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "VariableState(\n",
       "  type=RngCount,\n",
       "  value=Array(149, dtype=uint32),\n",
       "  tag='default'\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "VariableState(\n",
       "  type=RngKey,\n",
       "  value=Array((), dtype=key<fry>) overlaying:\n",
       "  [0 0],\n",
       "  tag='default'\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "VariableState(\n",
       "  type=RngCount,\n",
       "  value=Array(162, dtype=uint32),\n",
       "  tag='default'\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt2 import GPT\n",
    "import optax\n",
    "import flax.nnx as nnx\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import datasets\n",
    "\n",
    "model = GPT.from_pretrained(\"gpt2\")\n",
    "model.train()\n",
    "tx = optax.adamw(learning_rate=1e-4, weight_decay=1e-4)\n",
    "optimizer = nnx.Optimizer(model, tx)\n",
    "metrics = nnx.MultiMetric(\n",
    "    accuracy=nnx.metrics.Accuracy(),\n",
    "    loss=nnx.metrics.Average(\"loss\"),\n",
    ")\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "batch_size = 6\n",
    "block_size = 1024\n",
    "\n",
    "data = datasets.load_dataset(path=\"Trelis/tiny-shakespeare\")\n",
    "train_data = \"\\n\".join([x[\"Text\"] for x in data[\"train\"]])\n",
    "train_data = enc.encode_ordinary(train_data)\n",
    "train_data = np.array(train_data, dtype=np.uint16)\n",
    "val_data = \"\\n\".join([x[\"Text\"] for x in data[\"test\"]])\n",
    "val_data = enc.encode_ordinary(val_data)\n",
    "val_data = np.array(val_data, dtype=np.uint16)\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model: GPT, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
    "    x, y = batch\n",
    "\n",
    "    def loss_fn(model: GPT):\n",
    "        logits = model(x)\n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "            logits.reshape([-1, logits.shape[-1]]), y.reshape([-1])\n",
    "        ).mean()\n",
    "        return loss, logits\n",
    "\n",
    "    grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(model)\n",
    "    metrics.update(loss=loss, logits=logits, labels=y)\n",
    "    optimizer.update(grads)\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = np.random.randint(len(data) - block_size, size=(batch_size,))\n",
    "    x = np.stack([data[i : i + block_size].astype(np.int32) for i in ix])\n",
    "    y = np.stack([data[i + 1 : i + 1 + block_size].astype(np.int32) for i in ix])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "nnx.state(model).flat_state()[(\"drop\", \"rngs\", \"default\", \"key\")]\n",
    "nnx.state(model).flat_state()[(\"drop\", \"rngs\", \"default\", \"count\")]\n",
    "train_step(model, optimizer, metrics, get_batch(\"train\"))\n",
    "nnx.state(model).flat_state()[(\"drop\", \"rngs\", \"default\", \"key\")]\n",
    "nnx.state(model).flat_state()[(\"drop\", \"rngs\", \"default\", \"count\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training does not appear to modify the key\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
