{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RngKey(\n",
       "  value=Array((), dtype=key<fry>) overlaying:\n",
       "  [0 0],\n",
       "  tag='default'\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flax.nnx as nnx\n",
    "\n",
    "nnx.Rngs(0).default.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2 import GPT\n",
    "import optax\n",
    "import flax.nnx as nnx\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model: GPT, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
    "    x, y = batch\n",
    "\n",
    "    def loss_fn(model: GPT):\n",
    "        logits = model(x)\n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "            logits.reshape([-1, logits.shape[-1]]), y.reshape([-1])\n",
    "        ).mean()\n",
    "        return loss, logits\n",
    "\n",
    "    grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(model)\n",
    "    metrics.update(loss=loss, logits=logits, labels=y)\n",
    "    optimizer.update(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of prepared JAX modules dict: 89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': Array(0.3976237, dtype=float32),\n",
       " 'loss': Array(4.034092, dtype=float32)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': Array(0.38875327, dtype=float32),\n",
       " 'loss': Array(3.8402543, dtype=float32)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt2 import GPT\n",
    "import optax\n",
    "import flax.nnx as nnx\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import datasets\n",
    "\n",
    "model = GPT.from_pretrained(\"gpt2\")\n",
    "model.train()\n",
    "tx = optax.adamw(learning_rate=1e-4, weight_decay=1e-4)\n",
    "optimizer = nnx.Optimizer(model, tx)\n",
    "metrics = nnx.MultiMetric(\n",
    "    accuracy=nnx.metrics.Accuracy(),\n",
    "    loss=nnx.metrics.Average(\"loss\"),\n",
    ")\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "batch_size = 6\n",
    "block_size = 1024\n",
    "\n",
    "data = datasets.load_dataset(path=\"Trelis/tiny-shakespeare\")\n",
    "train_data = \"\\n\".join([x[\"Text\"] for x in data[\"train\"]])\n",
    "train_data = enc.encode_ordinary(train_data)\n",
    "train_data = np.array(train_data, dtype=np.uint16)\n",
    "val_data = \"\\n\".join([x[\"Text\"] for x in data[\"test\"]])\n",
    "val_data = enc.encode_ordinary(val_data)\n",
    "val_data = np.array(val_data, dtype=np.uint16)\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = np.random.randint(len(data) - block_size, size=(batch_size,))\n",
    "    x = np.stack([data[i : i + block_size].astype(np.int32) for i in ix])\n",
    "    y = np.stack([data[i + 1 : i + 1 + block_size].astype(np.int32) for i in ix])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train_step(model, optimizer, metrics, get_batch(\"train\"))\n",
    "metrics.compute()\n",
    "\n",
    "train_step(model, optimizer, metrics, get_batch(\"train\"))\n",
    "metrics.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
